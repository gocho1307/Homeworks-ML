{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework IV\n",
    "\n",
    "Gonçalo Bárias (ist1103124) & Raquel Braunschweig (ist1102624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook mainly contains our solution for the programming and critical analysis section of the Homework (Part II). For the pen and paper section (Part I), we only include the numpy code used for the calculus. The full solution and details for Part I can be found on the pdf report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [11v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [6v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal, bernoulli\n",
    "\n",
    "y1 = np.array([1, 0, 0, 1])\n",
    "y2_y3 = np.array([[0.6, 0.1], [-0.4, 0.8], [0.2, 0.5], [0.4, -0.1]])\n",
    "\n",
    "pi_1, pi_2 = 0.5, 0.5\n",
    "p_1, p_2 = 0.3, 0.7\n",
    "mu_1, mu_2 = [1, 1], [0, 0]\n",
    "sigma_1, sigma_2 = [[2, 0.5], [0.5, 2]], [[1.5, 1], [1, 1.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation\n",
    "\n",
    "# y_1 (Bernoulli)\n",
    "p_y1_0_c1 = 1 - p_1\n",
    "p_y1_1_c1 = p_1\n",
    "p_y1_0_c2 = 1 - p_2\n",
    "p_y1_1_c2 = p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate for x_1:\n",
      "0.06657529920303393\n",
      "0.11961837142058572\n",
      "----------------------------\n",
      "Multivariate for x_2:\n",
      "0.05004888824270901\n",
      "0.0681905803254947\n",
      "----------------------------\n",
      "Multivariate for x_3:\n",
      "0.06837452355368487\n",
      "0.12958103481626038\n",
      "----------------------------\n",
      "Multivariate for x_4:\n",
      "0.059046993443730274\n",
      "0.12450008976589248\n"
     ]
    }
   ],
   "source": [
    "# y_2 and y_3 (Multivariate Gaussian)\n",
    "p_x1_c1_norm = multivariate_normal.pdf(y2_y3[0], mean=mu_1, cov=sigma_1)\n",
    "p_x1_c2_norm = multivariate_normal.pdf(y2_y3[0], mean=mu_2, cov=sigma_2)\n",
    "print(\"Multivariate for x_1:\")\n",
    "print(p_x1_c1_norm)\n",
    "print(p_x1_c2_norm)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_x2_c1_norm = multivariate_normal.pdf(y2_y3[1], mean=mu_1, cov=sigma_1)\n",
    "p_x2_c2_norm = multivariate_normal.pdf(y2_y3[1], mean=mu_2, cov=sigma_2)\n",
    "print(\"Multivariate for x_2:\")\n",
    "print(p_x2_c1_norm)\n",
    "print(p_x2_c2_norm)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_x3_c1_norm = multivariate_normal.pdf(y2_y3[2], mean=mu_1, cov=sigma_1)\n",
    "p_x3_c2_norm = multivariate_normal.pdf(y2_y3[2], mean=mu_2, cov=sigma_2)\n",
    "print(\"Multivariate for x_3:\")\n",
    "print(p_x3_c1_norm)\n",
    "print(p_x3_c2_norm)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_x4_c1_norm = multivariate_normal.pdf(y2_y3[3], mean=mu_1, cov=sigma_1)\n",
    "p_x4_c2_norm = multivariate_normal.pdf(y2_y3[3], mean=mu_2, cov=sigma_2)\n",
    "print(\"Multivariate for x_4:\")\n",
    "print(p_x4_c1_norm)\n",
    "print(p_x4_c2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posteriors for x_1:\n",
      "0.1925895872206616\n",
      "0.8074104127793383\n",
      "----------------------------\n",
      "Posteriors for x_2:\n",
      "0.6313451161603738\n",
      "0.36865488383962625\n",
      "----------------------------\n",
      "Posteriors for x_3:\n",
      "0.5518112814848372\n",
      "0.4481887185151628\n",
      "----------------------------\n",
      "Posteriors for x_4:\n",
      "0.16892423384960822\n",
      "0.8310757661503917\n"
     ]
    }
   ],
   "source": [
    "# p_ck_xi (All of the posteriors for each observation)\n",
    "p_c1_x1 = (p_y1_1_c1 * p_x1_c1_norm * pi_1) / (p_y1_1_c1 * p_x1_c1_norm * pi_1 + p_y1_1_c2 * p_x1_c2_norm * pi_2)\n",
    "p_c2_x1 = (p_y1_1_c2 * p_x1_c2_norm * pi_2) / (p_y1_1_c1 * p_x1_c1_norm * pi_1 + p_y1_1_c2 * p_x1_c2_norm * pi_2)\n",
    "print(\"Posteriors for x_1:\")\n",
    "print(p_c1_x1)\n",
    "print(p_c2_x1)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_c1_x2 = (p_y1_0_c1 * p_x2_c1_norm * pi_1) / (p_y1_0_c1 * p_x2_c1_norm * pi_1 + p_y1_0_c2 * p_x2_c2_norm * pi_2)\n",
    "p_c2_x2 = (p_y1_0_c2 * p_x2_c2_norm * pi_2) / (p_y1_0_c1 * p_x2_c1_norm * pi_1 + p_y1_0_c2 * p_x2_c2_norm * pi_2)\n",
    "print(\"Posteriors for x_2:\")\n",
    "print(p_c1_x2)\n",
    "print(p_c2_x2)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_c1_x3 = (p_y1_0_c1 * p_x3_c1_norm * pi_1) / (p_y1_0_c1 * p_x3_c1_norm * pi_1 + p_y1_0_c2 * p_x3_c2_norm * pi_2)\n",
    "p_c2_x3 = (p_y1_0_c2 * p_x3_c2_norm * pi_2) / (p_y1_0_c1 * p_x3_c1_norm * pi_1 + p_y1_0_c2 * p_x3_c2_norm * pi_2)\n",
    "print(\"Posteriors for x_3:\")\n",
    "print(p_c1_x3)\n",
    "print(p_c2_x3)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "p_c1_x4 = (p_y1_1_c1 * p_x4_c1_norm * pi_1) / (p_y1_1_c1 * p_x4_c1_norm * pi_1 + p_y1_1_c2 * p_x4_c2_norm * pi_2)\n",
    "p_c2_x4 = (p_y1_1_c2 * p_x4_c2_norm * pi_2) / (p_y1_1_c1 * p_x4_c1_norm * pi_1 + p_y1_1_c2 * p_x4_c2_norm * pi_2)\n",
    "print(\"Posteriors for x_4:\")\n",
    "print(p_c1_x4)\n",
    "print(p_c2_x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New bernoulli p_1: 0.23403948408541084\n",
      "New mu_1 for multivariate: [0.026509   0.50712978]\n",
      "New sigma_1 for multivariate:\n",
      "[[ 0.14136501 -0.10540546]\n",
      " [-0.10540546  0.0960526 ]]\n",
      "New pi_1 prior: 0.3861675546788702\n",
      "-------------------------------------------------------\n",
      "New bernoulli p_2: 0.6673181710330361\n",
      "New mu_2 for multivariate: [0.30914476 0.2104205 ]\n",
      "New sigma_2 for multivariate:\n",
      "[[ 0.10829305 -0.08865175]\n",
      " [-0.08865175  0.1041233 ]]\n",
      "New pi_2 prior: 0.6138324453211298\n"
     ]
    }
   ],
   "source": [
    "# Maximization\n",
    "\n",
    "N_1 = p_c1_x1 + p_c1_x2 + p_c1_x3 + p_c1_x4\n",
    "N_2 = p_c2_x1 + p_c2_x2 + p_c2_x3 + p_c2_x4\n",
    "\n",
    "p_new_1 = (p_c1_x1 * y1[0] + p_c1_x2 * y1[1]\n",
    "          + p_c1_x3 * y1[2] + p_c1_x4 * y1[3]) / N_1\n",
    "p_new_2 = (p_c2_x1 * y1[0] + p_c2_x2 * y1[1]\n",
    "          + p_c2_x3 * y1[2] + p_c2_x4 * y1[3]) / N_2\n",
    "\n",
    "mu_new_1 = (p_c1_x1 * y2_y3[0] + p_c1_x2 * y2_y3[1] \n",
    "           + p_c1_x3 * y2_y3[2] + p_c1_x4 * y2_y3[3]) / N_1\n",
    "mu_new_2 = (p_c2_x1 * y2_y3[0] + p_c2_x2 * y2_y3[1]\n",
    "           + p_c2_x3 * y2_y3[2] + p_c2_x4 * y2_y3[3]) / N_2\n",
    "\n",
    "sigma_new_1 = (p_c1_x1 * np.matmul(np.matrix(y2_y3[0] - mu_new_1).T, np.matrix(y2_y3[0] - mu_new_1))\n",
    "              + p_c1_x2 * np.matmul(np.matrix(y2_y3[1] - mu_new_1).T, np.matrix(y2_y3[1] - mu_new_1))\n",
    "              + p_c1_x3 * np.matmul(np.matrix(y2_y3[2] - mu_new_1).T, np.matrix(y2_y3[2] - mu_new_1))\n",
    "              + p_c1_x4 * np.matmul(np.matrix(y2_y3[3] - mu_new_1).T, np.matrix(y2_y3[3] - mu_new_1))) / N_1\n",
    "sigma_new_2 = (p_c2_x1 * np.matmul(np.matrix(y2_y3[0] - mu_new_2).T, np.matrix(y2_y3[0] - mu_new_2))\n",
    "              + p_c2_x2 * np.matmul(np.matrix(y2_y3[1] - mu_new_2).T, np.matrix(y2_y3[1] - mu_new_2))\n",
    "              + p_c2_x3 * np.matmul(np.matrix(y2_y3[2] - mu_new_2).T, np.matrix(y2_y3[2] - mu_new_2))\n",
    "              + p_c2_x4 * np.matmul(np.matrix(y2_y3[3] - mu_new_2).T, np.matrix(y2_y3[3] - mu_new_2))) / N_2\n",
    "\n",
    "pi_new_1 = N_1 / (N_1 + N_2)\n",
    "pi_new_2 = N_2 / (N_1 + N_2)\n",
    "\n",
    "print(f\"New bernoulli p_1: {p_new_1}\")\n",
    "print(f\"New mu_1 for multivariate: {mu_new_1}\")\n",
    "print(\"New sigma_1 for multivariate:\")\n",
    "print(sigma_new_1)\n",
    "print(f\"New pi_1 prior: {pi_new_1}\")\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(f\"New bernoulli p_2: {p_new_2}\")\n",
    "print(f\"New mu_2 for multivariate: {mu_new_2}\")\n",
    "print(\"New sigma_2 for multivariate:\")\n",
    "print(sigma_new_2)\n",
    "print(f\"New pi_2 prior: {pi_new_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [2v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate for x_new:\n",
      "0.027075573673303183\n",
      "0.06843088109574752\n",
      "----------------------------\n",
      "Posteriors for x_new:\n",
      "0.08028950846197516\n",
      "0.9197104915380249\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "y2_y3_xnew= [0.3, 0.7]\n",
    "\n",
    "# E-step\n",
    "p_xnew_c1_norm = multivariate_normal.pdf(y2_y3_xnew, mean=mu_new_1, cov=sigma_new_1)\n",
    "p_xnew_c2_norm = multivariate_normal.pdf(y2_y3_xnew, mean=mu_new_2, cov=sigma_new_2)\n",
    "\n",
    "print(\"Multivariate for x_new:\")\n",
    "print(p_xnew_c1_norm)\n",
    "print(p_xnew_c2_norm)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Calculate posterioris\n",
    "p_c1_xnew = (p_new_1 * p_xnew_c1_norm * pi_new_1) / (p_new_1 * p_xnew_c1_norm * pi_new_1 + p_new_2 * p_xnew_c2_norm * pi_new_2)\n",
    "p_c2_xnew = (p_new_2 * p_xnew_c2_norm * pi_new_2) / (p_new_1 * p_xnew_c1_norm * pi_new_1 + p_new_2 * p_xnew_c2_norm * pi_new_2)\n",
    "\n",
    "print(\"Posteriors for x_new:\")\n",
    "print(p_c1_xnew)\n",
    "print(p_c2_xnew)\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [2.5v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 1:\n",
      "Posterior for class 1: 0.1329686274598629\n",
      "Posterior for class 2: 0.8670313725401372\n",
      "----------------------------------------\n",
      "x 2:\n",
      "Posterior for class 1: 0.8997775860290207\n",
      "Posterior for class 2: 0.10022241397097939\n",
      "----------------------------------------\n",
      "x 3:\n",
      "Posterior for class 1: 0.6657785222758353\n",
      "Posterior for class 2: 0.33422147772416466\n",
      "----------------------------------------\n",
      "x 4:\n",
      "Posterior for class 1: 0.017740392840278993\n",
      "Posterior for class 2: 0.982259607159721\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate the new posteriors\n",
    "\n",
    "observations = np.array([[1, 0.6, 0.1],[0, -0.4, 0.8],[0, 0.2, 0.5],[1, 0.4, -0.1]])\n",
    "\n",
    "new_posteriors = []\n",
    "for obs in observations:\n",
    "    likelihood_1 = pi_new_1 * bernoulli.pmf(obs[0], p_new_1) * multivariate_normal.pdf(obs[1:], mean=mu_new_1, cov=sigma_new_1)\n",
    "    likelihood_2 = pi_new_2 * bernoulli.pmf(obs[0], p_new_2) * multivariate_normal.pdf(obs[1:], mean=mu_new_2, cov=sigma_new_2)\n",
    "    \n",
    "    marginal_likelihood = likelihood_1 + likelihood_2\n",
    "    \n",
    "    posterior_1 = likelihood_1 / marginal_likelihood\n",
    "    posterior_2 = likelihood_2 / marginal_likelihood\n",
    "    \n",
    "    posterior_1 /= (posterior_1 + posterior_2)\n",
    "    posterior_2 /= (posterior_1 + posterior_2)\n",
    "    \n",
    "    new_posteriors.append((posterior_1, posterior_2))\n",
    "\n",
    "# Display the posteriors\n",
    "for i, (posterior_1, posterior_2) in enumerate(new_posteriors):\n",
    "    print(f\"x {i+1}:\")\n",
    "    print(f\"Posterior for class 1:\", posterior_1)\n",
    "    print(f\"Posterior for class 2:\", posterior_2)\n",
    "    print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 1:\n",
      "Si: 0.8222222222222223\n",
      "x 2:\n",
      "Si: 0.6666666666666666\n",
      "x 3:\n",
      "Si: 0.4999999999999999\n",
      "x 4:\n",
      "Si: 0.8222222222222223\n",
      "silhouette for c_1:\n",
      "0.5833333333333333\n",
      "----------------------------------------\n",
      "silhouette for c_2:\n",
      "0.8222222222222223\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cluster_of_obs = [2, 1, 1, 2]\n",
    "\n",
    "# Define manhattan distance funcion\n",
    "def manhattan_distance(point1, point2):\n",
    "    return np.sum(np.abs(np.array(point1) - np.array(point2)))\n",
    "\n",
    "silhouette_scores = []\n",
    "for i, observation in enumerate(observations):\n",
    "    a_i = 0\n",
    "    b_i = 0\n",
    "    for j, observation in enumerate(observations):\n",
    "        if i != j and cluster_of_obs[i] == cluster_of_obs[j]:\n",
    "            a_i += manhattan_distance(observations[i], observations[j])\n",
    "        elif cluster_of_obs[i] != cluster_of_obs[j]:\n",
    "            b_i += manhattan_distance(observations[i], observations[j])\n",
    "    \n",
    "    b_i = b_i/2 # Because there are 2 observations in the opposite cluster\n",
    "    silhouette_scores.append((b_i - a_i) / max(a_i, b_i))\n",
    "\n",
    "for i, si in enumerate(silhouette_scores):\n",
    "    print(f\"x {i+1}:\")\n",
    "    print(f\"Si:\", si)\n",
    "    \n",
    "silhouette_c1 = (silhouette_scores[1] + silhouette_scores[2]) / 2\n",
    "silhouette_c2 = (silhouette_scores[0] + silhouette_scores[3]) / 2\n",
    "\n",
    "print(\"silhouette for c_1:\")\n",
    "print(silhouette_c1)\n",
    "print(\"-\"*40)\n",
    "print(\"silhouette for c_2:\")\n",
    "print(silhouette_c2)\n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Programming and critical analysis [9v]\n",
    "\n",
    "**Recall the `column_diagnosis.arff` dataset from previous homeworks. For the following exercises,\n",
    "normalize the data using sklearn's `MinMaxScaler`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [4v]\n",
    "\n",
    "**Using `sklearn`, apply `k`-means clustering fully unsupervisedly on the normalized data with\n",
    "k ∈ {2,3,4,5} (`random=0` and remaining parameters as default). Assess the silhouette and purity of\n",
    "the produced solutions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [2v]\n",
    "\n",
    "**Consider the application of PCA after the data normalization:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Identify the variability explained by the top two principal components.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. For each one of these two components, sort the input variables by relevance by\n",
    "inspecting the absolute weights of the linear projection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [2v]\n",
    "\n",
    "**Visualize side-by-side the data using: i) the ground diagnoses, and ii) the __previously__ learned\n",
    "k = 3 clustering solution. To this end, projected the normalized data onto a 2-dimensional data\n",
    "space using PCA and then color observations using the reference and cluster annotations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [1v]\n",
    "\n",
    "**Considering the results from questions (1) and (3), identify two ways on how clustering can\n",
    "be used to characterize the population of ill and healthy individuals.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
