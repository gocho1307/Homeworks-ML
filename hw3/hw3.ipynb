{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III\n",
    "\n",
    "Gonçalo Bárias (ist1103124) & Raquel Braunschweig (ist1102624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook mainly contains our solution for the programming and critical analysis section of the Homework (Part II). For the pen and paper section (Part I), we only include the numpy code used for the calculus. The full solution and details for Part I can be found on the pdf report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [12v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [6v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_function(x, c):\n",
    "    return mt.exp(-1 / 2 * mt.dist(x, c) ** 2)\n",
    "\n",
    "x = [[0.7, -0.3], [0.4, 0.5], [-0.2, 0.8], [-0.4, 0.3]]\n",
    "c = [[0, 0], [1, -1], [-1, 1]]\n",
    "z = [0.8, 0.6, 0.3, 0.3]\n",
    "\n",
    "phi_matrix = []\n",
    "for x_val in x:\n",
    "    phi_matrix.append([1])  # phi_0 is always 1\n",
    "    for c_j in c:\n",
    "        phi_matrix[-1].append(basis_function(x_val, c_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_matrix = np.array(phi_matrix)\n",
    "phi_matrix_T = phi_matrix.transpose()\n",
    "\n",
    "a = np.matmul(phi_matrix_T, phi_matrix)\n",
    "b = np.add(a, 0.1 * np.identity(4))\n",
    "c = np.linalg.pinv(b)\n",
    "d = np.matmul(c, phi_matrix_T)\n",
    "\n",
    "w = np.matmul(d, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = np.matmul(phi_matrix, w)\n",
    "the_sum = np.sum(np.square(np.subtract(z, z_hat)))\n",
    "RMSE = mt.sqrt(1 / 4 * the_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** 1a.\n",
      "-- Phi -----------------------------------\n",
      "[[1.      0.74826 0.74826 0.10127]\n",
      " [1.      0.81465 0.27117 0.33121]\n",
      " [1.      0.71177 0.09633 0.71177]\n",
      " [1.      0.8825  0.16122 0.65377]]\n",
      "-- Phi^T ---------------------------------\n",
      "[[1.      1.      1.      1.     ]\n",
      " [0.74826 0.81465 0.71177 0.8825 ]\n",
      " [0.74826 0.27117 0.09633 0.16122]\n",
      " [0.10127 0.33121 0.71177 0.65377]]\n",
      "-- Phi^T*Phi -----------------------------\n",
      "[[4.      3.15718 1.27698 1.79802]\n",
      " [3.15718 2.50897 0.99165 1.42916]\n",
      " [1.27698 0.99165 0.6687  0.33955]\n",
      " [1.79802 1.42916 0.33955 1.05399]]\n",
      "-- Phi^T*Phi + 0.1I ----------------------\n",
      "[[4.1     3.15718 1.27698 1.79802]\n",
      " [3.15718 2.60897 0.99165 1.42916]\n",
      " [1.27698 0.99165 0.7687  0.33955]\n",
      " [1.79802 1.42916 0.33955 1.15399]]\n",
      "-- (Phi^T*Phi + 0.1I)^(-1) ---------------\n",
      "[[ 4.54826 -3.77682 -1.86117 -1.86155]\n",
      " [-3.77682  5.98285 -0.88543 -1.26432]\n",
      " [-1.86117 -0.88543  4.33276  2.72156]\n",
      " [-1.86155 -1.26432  2.72156  4.53204]]\n",
      "-- (Phi^T*Phi + 0.1I)^(-1) * Phi^T -------\n",
      "[[ 0.14105  0.35022  0.35575 -0.30185]\n",
      " [-0.09064  0.43823 -0.50361  0.5337 ]\n",
      " [ 0.99394 -0.50615 -0.1369  -0.16477]\n",
      " [-0.31222 -0.65246  0.72647  0.42436]]\n",
      "-- w -------------------------------------\n",
      "[ 0.33914  0.19945  0.40096 -0.296  ]\n",
      "\n",
      "*************** 1b.\n",
      "-- z_hat ---------------------------------\n",
      "[0.75844 0.51232 0.30905 0.38629]\n",
      "-- the_sum -------------------------------\n",
      "0.01694\n",
      "-- RMSE ----------------------------------\n",
      "0.06508\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** 1a.\")\n",
    "print(\"-- Phi -----------------------------------\")\n",
    "print(np.round(phi_matrix, 5))\n",
    "print(\"-- Phi^T ---------------------------------\")\n",
    "print(np.round(phi_matrix_T, 5))\n",
    "print(\"-- Phi^T*Phi -----------------------------\")\n",
    "print(np.round(a, 5))\n",
    "print(\"-- Phi^T*Phi + 0.1I ----------------------\")\n",
    "print(np.round(b, 5))\n",
    "print(\"-- (Phi^T*Phi + 0.1I)^(-1) ---------------\")\n",
    "print(np.round(c, 5))\n",
    "print(\"-- (Phi^T*Phi + 0.1I)^(-1) * Phi^T -------\")\n",
    "print(np.round(d, 5))\n",
    "print(\"-- w -------------------------------------\")\n",
    "print(np.round(w, 5))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"*************** 1b.\")\n",
    "print(\"-- z_hat ---------------------------------\")\n",
    "print(np.round(z_hat, 5))\n",
    "print(\"-- the_sum -------------------------------\")\n",
    "print(round(the_sum, 5))\n",
    "print(\"-- RMSE ----------------------------------\")\n",
    "print(round(RMSE, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [6v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define variables\n",
    "W1 = np.array([[1, 1, 1, 1], [1, 1, 2, 1], [1, 1, 1, 1]])\n",
    "b1 = np.array([[1], [1], [1]])\n",
    "\n",
    "W2 = np.array([[1, 4, 1], [1, 1, 1]])\n",
    "b2 = np.array([[1], [1]])\n",
    "\n",
    "W3 = np.array([[1, 1], [3, 1], [1, 1]])\n",
    "b3 = np.array([[1], [1], [1]])\n",
    "\n",
    "x1 = np.array([[1], [1], [1], [1]])\n",
    "x2 = np.array([[1], [0], [0], [-1]])\n",
    "\n",
    "# Define the activation function\n",
    "def activation_function(x):\n",
    "    return np.tanh(0.5 * x - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Forward Pass for x1:\n",
      "z1:\n",
      "[[5]\n",
      " [6]\n",
      " [5]]\n",
      "a1:\n",
      "[[0.46212]\n",
      " [0.76159]\n",
      " [0.46212]]\n",
      "z2:\n",
      "[[4.97061]\n",
      " [2.68583]]\n",
      "a2:\n",
      "[[ 0.45048]\n",
      " [-0.57642]]\n",
      "z3:\n",
      "[[0.87406]\n",
      " [1.77503]\n",
      " [0.87406]]\n",
      "a3:\n",
      "[[-0.9159 ]\n",
      " [-0.80494]\n",
      " [-0.9159 ]]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Forward Pass\n",
    "# for x1\n",
    "z1_1 = np.dot(W1, x1) + b1\n",
    "a1_1 = activation_function(z1_1)\n",
    "\n",
    "z2_1 = np.dot(W2, a1_1) + b2\n",
    "a2_1 = activation_function(z2_1)\n",
    "\n",
    "z3_1 = np.dot(W3, a2_1) + b3\n",
    "a3_1 = activation_function(z3_1)\n",
    "\n",
    "# for x2\n",
    "z1_2 = np.dot(W1, x2) + b1\n",
    "a1_2 = activation_function(z1_2)\n",
    "\n",
    "z2_2 = np.dot(W2, a1_2) + b2\n",
    "a2_2 = activation_function(z2_2)\n",
    "\n",
    "z3_2 = np.dot(W3, a2_2) + b3\n",
    "a3_2 = activation_function(z3_2)\n",
    "\n",
    "print(\"**Forward Pass for x1:\")\n",
    "print(\"z1:\")\n",
    "print(z1_1)\n",
    "print(\"a1:\")\n",
    "print(np.round(a1_1, 5))\n",
    "print(\"z2:\")\n",
    "print(np.round(z2_1, 5))\n",
    "print(\"a2:\")\n",
    "print(np.round(a2_1, 5))\n",
    "print(\"z3:\")\n",
    "print(np.round(z3_1, 5))\n",
    "print(\"a3:\")\n",
    "print(np.round(a3_1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Forward Pass for x2:\n",
      "z1:\n",
      "[[1]\n",
      " [1]\n",
      " [1]]\n",
      "a1:\n",
      "[[-0.90515]\n",
      " [-0.90515]\n",
      " [-0.90515]]\n",
      "z2:\n",
      "[[-4.43089]\n",
      " [-1.71544]]\n",
      "a2:\n",
      "[[-0.99956]\n",
      " [-0.99343]]\n",
      "z3:\n",
      "[[-0.993  ]\n",
      " [-2.99212]\n",
      " [-0.993  ]]\n",
      "a3:\n",
      "[[-0.98652]\n",
      " [-0.99816]\n",
      " [-0.98652]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"**Forward Pass for x2:\")\n",
    "print(\"z1:\")\n",
    "print(np.round(z1_2, 5))\n",
    "print(\"a1:\")\n",
    "print(np.round(a1_2, 5))\n",
    "print(\"z2:\")\n",
    "print(np.round(z2_2, 5))\n",
    "print(\"a2:\")\n",
    "print(np.round(a2_2, 5))\n",
    "print(\"z3:\")\n",
    "print(np.round(z3_2, 5))\n",
    "print(\"a3:\")\n",
    "print(np.round(a3_2, 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Backpropagation for x1:\n",
      "Delta 3:\n",
      "[[ 0.00678]\n",
      " [-0.31773]\n",
      " [ 0.00678]]\n",
      "Delta 2:\n",
      "[[-0.37448]\n",
      " [-0.10156]]\n",
      "Delta 1:\n",
      "[[-0.18719]\n",
      " [-0.33587]\n",
      " [-0.18719]]\n",
      "**Backpropagation for x2:\n",
      "Delta 3:\n",
      "[[-0.0266 ]\n",
      " [ 0.     ]\n",
      " [ 0.00018]]\n",
      "Delta 2:\n",
      "[[-1.0e-05]\n",
      " [-1.7e-04]]\n",
      "Delta 1:\n",
      "[[-2.e-05]\n",
      " [-2.e-05]\n",
      " [-2.e-05]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Backpropagation\n",
    "# Define the derivative function\n",
    "def derivative_function(x):\n",
    "    return np.square(1 / np.cosh(0.5 * x - 2)) * 0.5\n",
    "\n",
    "z_1 =  np.array([[-1], [1], [-1]])\n",
    "z_2 =  np.array([[1], [-1], [-1]])\n",
    "\n",
    "delta3_1 = np.multiply(a3_1 - z_1, derivative_function(z3_1))\n",
    "delta2_1 = np.multiply(np.dot(W3.T, delta3_1), derivative_function(z2_1))\n",
    "delta1_1 = np.multiply(np.dot(W2.T, delta2_1), derivative_function(z1_1))\n",
    "\n",
    "print(\"**Backpropagation for x1:\")\n",
    "print(\"Delta 3:\")\n",
    "print(np.round(delta3_1, 5))\n",
    "print(\"Delta 2:\")\n",
    "print(np.round(delta2_1, 5))\n",
    "print(\"Delta 1:\")\n",
    "print(np.round(delta1_1, 5))\n",
    "\n",
    "delta3_2 = np.multiply(a3_2 - z_2, derivative_function(z3_2))\n",
    "delta2_2 = np.multiply(np.dot(W3.T, delta3_2), derivative_function(z2_2))\n",
    "delta1_2 = np.multiply(np.dot(W2.T, delta2_2), derivative_function(z1_2))\n",
    "\n",
    "print(\"**Backpropagation for x2:\")\n",
    "print(\"Delta 3:\")\n",
    "print(np.round(delta3_2, 5))\n",
    "print(\"Delta 2:\")\n",
    "print(np.round(delta2_2, 5))\n",
    "print(\"Delta 1:\")\n",
    "print(np.round(delta1_2, 5))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[ 0.02964  0.02252]\n",
      " [-0.14314  0.18315]\n",
      " [ 0.00287 -0.00408]]\n",
      "2\n",
      "[[-0.17304 -0.28519 -0.17304]\n",
      " [-0.04678 -0.07719 -0.04678]]\n",
      "1\n",
      "[[-0.18721 -0.18719 -0.18719 -0.18717]\n",
      " [-0.33589 -0.33587 -0.33587 -0.33585]\n",
      " [-0.18721 -0.18719 -0.18719 -0.18717]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caculate derivatives\n",
    "deriv_3 = np.dot(delta3_1, a2_1.T) + np.dot(delta3_2, a2_2.T)\n",
    "deriv_2 = np.dot(delta2_1, a1_1.T) + np.dot(delta2_2, a1_2.T)\n",
    "deriv_1 = np.dot(delta1_1, x1.T) + np.dot(delta1_2, x2.T)\n",
    "\n",
    "print(\"3\")\n",
    "print(np.round(deriv_3, 5))\n",
    "print(\"2\")\n",
    "print(np.round(deriv_2, 5))\n",
    "print(\"1\")\n",
    "print(np.round(deriv_1, 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1:\n",
      "[[1.01872 1.01872 1.01872 1.01872]\n",
      " [1.03359 1.03359 2.03359 1.03359]\n",
      " [1.01872 1.01872 1.01872 1.01872]]\n",
      "[[1.01872]\n",
      " [1.03359]\n",
      " [1.01872]]\n",
      "For 2:\n",
      "[[1.0173  4.02852 1.0173 ]\n",
      " [1.00468 1.00772 1.00468]]\n",
      "[[1.03745]\n",
      " [1.01017]]\n",
      "For 3:\n",
      "[[0.99704 0.99775]\n",
      " [3.01431 0.98169]\n",
      " [0.99971 1.00041]]\n",
      "[[1.00198]\n",
      " [1.03177]\n",
      " [0.9993 ]]\n"
     ]
    }
   ],
   "source": [
    "# Final step: calculate new weights and bias\n",
    "W1_new = W1 - 0.1 * deriv_1\n",
    "W2_new = W2 - 0.1 * deriv_2\n",
    "W3_new = W3 - 0.1 * deriv_3\n",
    "\n",
    "b1_new = b1 - 0.1 * (delta1_1 + delta1_2) \n",
    "b2_new = b2 - 0.1 * (delta2_1 + delta2_2) \n",
    "b3_new = b3 - 0.1 * (delta3_1 + delta3_2) \n",
    "\n",
    "print(\"For 1:\")\n",
    "print(np.round(W1_new, 5))\n",
    "print(np.round(b1_new, 5))\n",
    "print(\"For 2:\")\n",
    "print(np.round(W2_new, 5))\n",
    "print(np.round(b2_new, 5))\n",
    "print(\"For 3:\")\n",
    "print(np.round(W3_new, 5))\n",
    "print(np.round(b3_new, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Programming and critical analysis [8v]\n",
    "\n",
    "**Consider the `winequality-red.csv` dataset (available at the webpage) where the goal is to estimate\n",
    "the quality (sensory appreciation) of a wine based on physicochemical inputs.**\n",
    "\n",
    "**Using a 80-20 training-test split with a fixed seed (`random_state=0`), you are asked to learn MLP\n",
    "regressors to answer the following questions.**\n",
    "\n",
    "**Given their stochastic behavior, average the performance of each MLP from 10 runs\n",
    "(for reproducibility consider seeding the MLPs with `random_state` ∈ {1..10}).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [3v]\n",
    "\n",
    "**Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation\n",
    "on all nodes, and early stopping with 20% of training data set aside for validation. All\n",
    "remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as\n",
    "default. Plot the distribution of the residues (in absolute value) using a histogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and prepare the dataset\n",
    "data = pd.read_csv(\"./data/winequality-red.csv\", sep=\";\")\n",
    "X, y = data.drop(\"quality\", axis=1), data[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Learn the MLP regressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10, 10), activation=\"relu\", early_stopping=True, \n",
    "                    validation_fraction=0.2, random_state=0)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Collect the residues\n",
    "y_pred = mlp.predict(X_test)\n",
    "residues = np.abs(np.array(y_pred) - np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Plot the distribution of the absolute residues\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residues, bins=20, color = \"#00bfc4\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Absolute Residues\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1.5v]\n",
    "\n",
    "**Since we are in the presence of a\n",
    "_integer regression_ task, a recommended trick is to\n",
    "round and bound estimates. Assess the impact of these operations on the MAE of the MLP\n",
    "learnt in the previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with rounded predictions: 0.43125\n",
      "MAE with bounded predictions: 0.4937438468885914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Train the MLP regressor, just like in the previous exercise\n",
    "data = pd.read_csv(\"./data/winequality-red.csv\", sep=\";\")\n",
    "X, y = data.drop(\"quality\", axis=1), data[\"quality\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "y_preds = []\n",
    "for i in range(1,11):\n",
    "    # Train the MLP regressor with a specific number of iterations\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', early_stopping=True, \n",
    "                        validation_fraction=0.2, random_state=i)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the target values on the test set\n",
    "    y_preds.append(mlp.predict(X_test))\n",
    "\n",
    "# Step 2: Apply rounding and bounding operations\n",
    "y_pred = np.mean(y_preds, axis=0)\n",
    "y_pred_rounded = np.round(y_pred)        # Round the predictions\n",
    "y_pred_bounded = np.clip(y_pred, 1, 10)  # Bound the predictions between 1 and 10\n",
    "\n",
    "# Step 3: Calculate MAE for both rounded and bounded predictions\n",
    "mae_rounded = mean_absolute_error(y_test, y_pred_rounded)\n",
    "mae_bounded = mean_absolute_error(y_test, y_pred_bounded)\n",
    "\n",
    "# Print the MAE for both cases\n",
    "print(f'MAE with rounded predictions: {mae_rounded}')\n",
    "print(f'MAE with bounded predictions: {mae_bounded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [1.5v]\n",
    "\n",
    "**Similarly assess the impact on RMSE from replacing early stopping by a well-defined\n",
    "number of iterations in {20,50,100,200} (where one iteration corresponds to a batch).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with 20 iterations: 1.0336201651006487\n",
      "RMSE with 50 iterations: 0.7060815422297181\n",
      "RMSE with 100 iterations: 0.6641845695241441\n",
      "RMSE with 200 iterations: 0.6393054830316605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train the MLP regressor, just like in the previous exercise\n",
    "data = pd.read_csv(\"./data/winequality-red.csv\", sep=\";\")\n",
    "X, y = data.drop(\"quality\", axis=1), data[\"quality\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "num_iterations, rmse_scores = [20, 50, 100, 200], []\n",
    "for num_iter in num_iterations:\n",
    "    y_preds = []\n",
    "    for i in range(1,11):\n",
    "        # Train the MLP regressor with a specific number of iterations\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', max_iter=num_iter,\n",
    "                            validation_fraction=0.2, random_state=i)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the target values on the test set\n",
    "        y_preds.append(mlp.predict(X_test))\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    y_pred = np.mean(y_preds, axis=0)\n",
    "    rmse_scores.append(mean_squared_error(y_test, y_pred, squared=False))\n",
    "\n",
    "# Print the RMSE for the different numbers of iterations\n",
    "for i, num_iter in enumerate(num_iterations):\n",
    "    print(f'RMSE with {num_iter} iterations: {rmse_scores[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [1.5v]\n",
    "\n",
    "**Critically comment the results obtained in previous question, hypothesizing at least\n",
    "one reason why early stopping favors and/or worsens performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
