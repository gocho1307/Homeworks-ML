{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III\n",
    "\n",
    "Gonçalo Bárias (ist1103124) & Raquel Braunschweig (ist1102624)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook mainly contains our solution for the programming and critical analysis section of the Homework (Part II). For the pen and paper section (Part I), we only include the numpy code used for the calculus. The full solution and details for Part I can be found on the pdf report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [12v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [6v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basis_function(x, c):\n",
    "    return mt.exp(-1 / 2 * mt.dist(x, c) ** 2)\n",
    "\n",
    "x = [[0.7, -0.3], [0.4, 0.5], [-0.2, 0.8], [-0.4, 0.3]]\n",
    "c = [[0, 0], [1, -1], [-1, 1]]\n",
    "z = [0.8, 0.6, 0.3, 0.3]\n",
    "\n",
    "x_matrix = []\n",
    "for x_val in x:\n",
    "    x_matrix.append([1]) # phi_0 is always 1\n",
    "    for c_j in c:\n",
    "        x_matrix[-1].append(basis_function(x_val, c_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(x_matrix)\n",
    "b = a.transpose()\n",
    "\n",
    "c = np.matmul(b, a)\n",
    "d = np.add(c, 0.1 * np.identity(4))\n",
    "e = np.linalg.pinv(d)\n",
    "f = np.matmul(e, b)\n",
    "\n",
    "w = np.matmul(f, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat = np.matmul(a, w)\n",
    "the_sum = np.sum(np.square(np.subtract(z, z_hat)))\n",
    "RMSE = round(mt.sqrt(1 / 4 * the_sum), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************** 1a.\")\n",
    "print(\"--X-------------------------------------\")\n",
    "print(np.round(a, 5))\n",
    "print(\"--X^T-----------------------------------\")\n",
    "print(np.round(b, 5))\n",
    "print(\"--X^T*X---------------------------------\")\n",
    "print(np.round(c, 5))\n",
    "print(\"--X^T*X + 0.1I--------------------------\")\n",
    "print(np.round(d, 5))\n",
    "print(\"--(X^T*X + 0.1I)^(-1)-------------------\")\n",
    "print(np.round(e, 5))\n",
    "print(\"--(X^T*X + 0.1I)^(-1) * X^T-------------\")\n",
    "print(np.round(f, 5))\n",
    "print(\"--W-------------------------------------\")\n",
    "print(np.round(w, 5))\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"*************** 1b.\")\n",
    "print(\"--z_hat---------------------------------\")\n",
    "print(np.round(z_hat, 5))\n",
    "print(\"--the_sum-------------------------------\")\n",
    "print(round(the_sum, 5)\n",
    "print(\"--RMSE----------------------------------\")\n",
    "print(round(RMSE, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [6v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define variables\n",
    "W1 = np.array([[1, 1, 1, 1], [1, 1, 2, 1], [1, 1, 1, 1]])\n",
    "b1 = np.array([[1], [1], [1]])\n",
    "\n",
    "W2 = np.array([[1, 4, 1], [1, 1, 1]])\n",
    "b2 = np.array([[1], [1]])\n",
    "\n",
    "W3 = np.array([[1, 1], [3, 1], [1, 1]])\n",
    "b3 = np.array([[1], [1], [1]])\n",
    "\n",
    "x1 = np.array([[1], [1], [1], [1]])\n",
    "x2 = np.array([[1], [0], [0], [-1]])\n",
    "\n",
    "# Define the activation function\n",
    "def activation_function(x):\n",
    "    return np.tanh(0.5 * x - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Forward Pass\n",
    "\n",
    "# for x1\n",
    "z1_1 = np.dot(W1, x1) + b1\n",
    "a1_1 = activation_function(z1_1)\n",
    "\n",
    "z2_1 = np.dot(W2, a1_1) + b2\n",
    "a2_1 = activation_function(z2_1)\n",
    "\n",
    "z3_1 = np.dot(W3, a2_1) + b3\n",
    "a3_1 = activation_function(z3_1)\n",
    "\n",
    "# for x2\n",
    "z1_2 = np.dot(W1, x2) + b1\n",
    "a1_2 = activation_function(z1_2)\n",
    "\n",
    "z2_2 = np.dot(W2, a1_2) + b2\n",
    "a2_2 = activation_function(z2_2)\n",
    "\n",
    "z3_2 = np.dot(W3, a2_2) + b3\n",
    "a3_2 = activation_function(z3_2)\n",
    "\n",
    "print(\"**Forward Pass for x1:\")\n",
    "print(\"z1:\")\n",
    "print(z1_1)\n",
    "print(\"a1:\")\n",
    "print(np.round(a1_1, 5))\n",
    "print(\"z2:\")\n",
    "print(np.round(z2_1, 5))\n",
    "print(\"a2:\")\n",
    "print(np.round(a2_1, 5))\n",
    "print(\"z3:\")\n",
    "print(np.round(z3_1, 5))\n",
    "print(\"a3:\")\n",
    "print(np.round(a3_1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"**Forward Pass for x2:\")\n",
    "print(\"z1:\")\n",
    "print(np.round(z1_2, 5))\n",
    "print(\"a1:\")\n",
    "print(np.round(a1_2, 5))\n",
    "print(\"z2:\")\n",
    "print(np.round(z2_2, 5))\n",
    "print(\"a2:\")\n",
    "print(np.round(a2_2, 5))\n",
    "print(\"z3:\")\n",
    "print(np.round(z3_2, 5))\n",
    "print(\"a3:\")\n",
    "print(np.round(a3_2, 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Backpropagation\n",
    "\n",
    "# Define the derivative function\n",
    "def derivative_function(x):\n",
    "    return np.square(1 / np.cosh(0.5 * x - 2)) * 0.5\n",
    "\n",
    "z_1 =  np.array([[-1], [1], [-1]])\n",
    "z_2 =  np.array([[1], [-1], [-1]])\n",
    "\n",
    "delta3_1 = np.multiply(a3_1 - z_1, derivative_function(z3_1))\n",
    "delta2_1 = np.multiply(np.dot(W3.T, delta3_1), derivative_function(z2_1))\n",
    "delta1_1 = np.multiply(np.dot(W2.T, delta2_1), derivative_function(z1_1))\n",
    "\n",
    "print(\"**Backpropagation for x1:\")\n",
    "print(\"Delta 3:\")\n",
    "print(np.round(delta3_1, 5))\n",
    "print(\"Delta 2:\")\n",
    "print(np.round(delta2_1, 5))\n",
    "print(\"Delta 1:\")\n",
    "print(np.round(delta1_1, 5))\n",
    "\n",
    "delta3_2 = np.multiply(a3_2 - z_2, derivative_function(z3_2))\n",
    "delta2_2 = np.multiply(np.dot(W3.T, delta3_2), derivative_function(z2_2))\n",
    "delta1_2 = np.multiply(np.dot(W2.T, delta2_2), derivative_function(z1_2))\n",
    "\n",
    "print(\"**Backpropagation for x2:\")\n",
    "print(\"Delta 3:\")\n",
    "print(np.round(delta3_2, 5))\n",
    "print(\"Delta 2:\")\n",
    "print(np.round(delta2_2, 5))\n",
    "print(\"Delta 1:\")\n",
    "print(np.round(delta1_2, 5))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate derivatives\n",
    "\n",
    "deriv_3 = np.dot(delta3_1, a2_1.T) + np.dot(delta3_2, a2_2.T)\n",
    "deriv_2 = np.dot(delta2_1, a1_1.T) + np.dot(delta2_2, a1_2.T)\n",
    "deriv_1 = np.dot(delta1_1, x1.T) + np.dot(delta1_2, x2.T)\n",
    "\n",
    "print(\"3\")\n",
    "print(np.round(deriv_3, 5))\n",
    "print(\"2\")\n",
    "print(np.round(deriv_2, 5))\n",
    "print(\"1\")\n",
    "print(np.round(deriv_1, 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final step: calculate new weights and bias\n",
    "\n",
    "W1_new = W1 - 0.1 * deriv_1\n",
    "W2_new = W2 - 0.1 * deriv_2\n",
    "W3_new = W3 - 0.1 * deriv_3\n",
    "\n",
    "b1_new = b1 - 0.1 * (delta1_1 + delta1_2) \n",
    "b2_new = b2 - 0.1 * (delta2_1 + delta2_2) \n",
    "b3_new = b3 - 0.1 * (delta3_1 + delta3_2) \n",
    "\n",
    "print(\"For 1:\")\n",
    "print(np.round(W1_new, 5))\n",
    "print(np.round(b1_new, 5))\n",
    "print(\"For 2:\")\n",
    "print(np.round(W2_new, 5))\n",
    "print(np.round(b2_new, 5))\n",
    "print(\"For 3:\")\n",
    "print(np.round(W3_new, 5))\n",
    "print(np.round(b3_new, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Programming and critical analysis [8v]\n",
    "\n",
    "**Consider the `winequality-red.csv` dataset (available at the webpage) where the goal is to estimate\n",
    "the quality (sensory appreciation) of a wine based on physicochemical inputs.**\n",
    "\n",
    "**Using a 80-20 training-test split with a fixed seed (`random_state=0`), you are asked to learn MLP\n",
    "regressors to answer the following questions.**\n",
    "\n",
    "**Given their stochastic behavior, average the performance of each MLP from 10 runs\n",
    "(for reproducibility consider seeding the MLPs with `random_state` ∈ {1..10}).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [3v]\n",
    "\n",
    "**Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation\n",
    "on all nodes, and early stopping with 20% of training data set aside for validation. All\n",
    "remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as\n",
    "default. Plot the distribution of the residues (in absolute value) using a histogram.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and prepare the dataset\n",
    "data = pd.read_csv('./data/winequality-red.csv', sep=';')  # Specify the delimiter as ';'\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Step 3: Define and train the MLP regressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', early_stopping=True,\n",
    "                             validation_fraction=0.2, random_state=0)\n",
    "\n",
    "# Step 4: Repeat the training process 10 times\n",
    "num_runs = 10\n",
    "mae_scores = []\n",
    "\n",
    "for seed in range(1, num_runs + 1):\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', early_stopping=True,\n",
    "                                 validation_fraction=0.2, random_state=seed)\n",
    "    mlp_regressor.fit(X_train, y_train)\n",
    "    y_pred = mlp_regressor.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mae_scores.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot the distribution of the absolute residues\n",
    "residues = np.abs(y_test - y_pred)\n",
    "plt.hist(residues, bins=20, edgecolor='k')\n",
    "plt.xlabel('Absolute Residues')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Absolute Residues')\n",
    "plt.show()\n",
    "\n",
    "# Print the average MAE\n",
    "average_mae = np.mean(mae_scores)\n",
    "print(f'Average MAE over {num_runs} runs: {average_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1.5v]\n",
    "\n",
    "**Since we are in the presence of a\n",
    "_integer regression_ task, a recommended trick is to\n",
    "round and bound estimates. Assess the impact of these operations on the MAE of the MLP\n",
    "learnt in previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Step 1: Train the MLP regressor as previously instructed\n",
    "# (Make sure you have already executed the code to train the MLP regressor)\n",
    "\n",
    "# Step 2: Predict the target values on the test set\n",
    "y_pred = mlp_regressor.predict(X_test)\n",
    "\n",
    "# Step 3: Apply rounding and bounding operations\n",
    "y_pred_rounded = np.round(y_pred)  # Round the predictions\n",
    "y_pred_bounded = np.clip(y_pred, 3, 8)  # Bound the predictions between 3 and 8\n",
    "\n",
    "# Step 4: Calculate MAE for both rounded and bounded predictions\n",
    "mae_rounded = mean_absolute_error(y_test, y_pred_rounded)\n",
    "mae_bounded = mean_absolute_error(y_test, y_pred_bounded)\n",
    "\n",
    "# Print the MAE for both cases\n",
    "print(f'MAE with rounded predictions: {mae_rounded}')\n",
    "print(f'MAE with bounded predictions: {mae_bounded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [1.5v]\n",
    "\n",
    "**Similarly assess the impact on RMSE from replacing early stopping by a well-defined\n",
    "number of iterations in {20,50,100,200} (where one iteration corresponds to a batch).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define a list of iterations to test\n",
    "num_iterations = [20, 50, 100, 200]\n",
    "rmse_scores = []\n",
    "\n",
    "for num_iter in num_iterations:\n",
    "    # Train the MLP regressor with a specific number of iterations\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=(10, 10), activation='relu', max_iter=num_iter,\n",
    "                                 validation_fraction=0.2, random_state=0)\n",
    "    mlp_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the target values on the test set\n",
    "    y_pred = mlp_regressor.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Print the RMSE for different numbers of iterations\n",
    "for i, num_iter in enumerate(num_iterations):\n",
    "    print(f'RMSE with {num_iter} iterations: {rmse_scores[i]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [1.5v]\n",
    "\n",
    "**Critically comment the results obtained in previous question, hypothesizing at least\n",
    "one reason why early stopping favors and/or worsens performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
