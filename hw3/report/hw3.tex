\documentclass[12pt]{article}
\usepackage[paper=letterpaper,margin=2cm]{geometry}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{newtxtext,newtxmath}
\usepackage{enumitem}
\usepackage{titling}
\usepackage{subfig,graphicx}
\usepackage[colorlinks=true]{hyperref}
\usepackage{multirow}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{float}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}
\begin{center}
\large{Aprendizagem 2023}\\
Homework III -- Group 28\\
\vskip 0.3cm
Gonçalo Bárias (ist1103124) \& Raquel Braunschweig (ist1102624)\vskip 1cm

\large{\textbf{Part I}: Pen and Paper}\normalsize
\end{center}

\begin{enumerate}[leftmargin=\labelsep]
    \item \textbf{Consider the problem of learning a regression model from 4 bivariate observations} \\

          \vskip -0.2cm
          \textbf{$\left\{\begin{pmatrix} 0.7 \\ -0.3 \end{pmatrix}, \begin{pmatrix} 0.4 \\ 0.5 \end{pmatrix}, \begin{pmatrix} -0.2 \\ 0.8 \end{pmatrix},
          \begin{pmatrix} -0.4 \\ 0.3 \end{pmatrix}\right\}$ with targets (0.8, 0.6, 0.3, 0.3)}.

    \begin{enumerate}
        \item \textbf{Given the radial basis function, $\varphi_j(x) = \text{exp}({ \frac{-\| \mathbf{x} - \mathbf{c}_j \|^2}{2} })$ that transforms
              the original space onto a new space characterized by the similarity of the original observastions to the following data points
              $\left\{ c_1 = \begin{pmatrix} 0 \\ 0 \end{pmatrix}, c_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}, c_3 = \begin{pmatrix} -1 \\ 1 \end{pmatrix}\right\}$. \\
              Learn the Ridge regression ($l_2$ regularization) using the closed solution with $\lambda$ = 0.1.}

              \vskip 0.3cm
              Gonçalo

        \item \textbf{Compute the training RMSE for the learnt regression.}

              \vskip 0.3cm
              Gonçalo
    \end{enumerate}

    \item \textbf{Consider a MLP classifier of three outcomes - A, B and C - characterized by the weights,} \\

          \vskip -0.2cm
          $W^{[1]} = \begin{pmatrix} 1 1 1 1 \\ 1 1 2 1 \\ 1 1 1 1\end{pmatrix}, b^{[1]} = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix},
          W^{[2]} = \begin{pmatrix} 1 4 1 \\ 1 1 1 \end{pmatrix}, b^{[2]} = \begin{pmatrix} 1 \\ 1 \end{pmatrix},
          W^{[3]} = \begin{pmatrix} 1 1 \\ 3 1 \\ 1 1\end{pmatrix}, b^{[3]} = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$ \\

          \textbf{the activation \[ f(x) = \frac{{e^{0.5x - 2} - e^{-0.5x + 2}}}{{e^{0.5x - 2} + e^{-0.5x + 2}}} = \tanh(0.5x - 2) \] for every unit, and squared error
          loss $\frac{1}{2} \|\mathbf{z} - \hat{\mathbf{z}}\|^{2}_{2}$. Perform one back gradient descent update (with learning rate $\eta = 0.1$) for training
          obvervations $x_1 = \begin{pmatrix} 1 \\ 1 \\ 1 \\ 1 \end{pmatrix}$ and $x_2 = \begin{pmatrix} 1 \\ 0 \\ 0 \\ -1 \end{pmatrix}$ with targets B and A,
          respectively.}

          \vskip 0.3cm
          Raquel
\end{enumerate}

\vskip 0.5cm

\begin{center}
\large{\textbf{Part II}: Programming and critical analysis}\normalsize
\end{center}

\noindent Considering the \texttt{winequality-red.csv} dataset (available at the webpage) where the goal is  to estimate the quality (sensory appreciation)
of a wine based on physicochemical inputs.

\vskip 0.3cm

\noindent Using a 80-20 training-test split with a fixed seed (\texttt{random\_state = 0}), you are asked to learn MLP
regressors to answer the following questions.

\noindent Given their stochastic behavior, average the performance of each MLP from 10 runs (for reproducibility consider seeding the MLPs with
\texttt{random\_state $\in$ \{1..10\}}).

\begin{enumerate}[leftmargin=\labelsep]
    \item \textbf{Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation
          on all nodes, and early stopping with 20\% of training data set aside for validation. All
          remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as
          default. Plot the distribution of the residues (in absolute value) using a histogram.}

          \vskip 0.3cm
          Blah

    \item \textbf{Since we are in the presence of a integer regression task, a recommended trick is to
          round and bound estimates. Assess the impact of these operations on the MAE of the MLP learnt in previous question.}

          \vskip 0.3cm
          Blah

    \item \textbf{Similarly assess the impact on RMSE from replacing early stopping by a well-defined
          number of iterations in \{20,50,100,200\} (where one iteration corresponds to a batch).}

           \vskip 0.3cm
           Blah

    \item \textbf{Critically comment the results obtained in previous question, hypothesizing at least
          one reason why early stopping favors and/or worsens performance}

          \vskip 0.3cm
          Blah
\end{enumerate}
\end{document}
